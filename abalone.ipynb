{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bcd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766a7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee36630",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "dataframe = read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcef0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataframe.values\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "data, labels = X.astype('float'), y.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44859ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.33, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fce406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=data.shape[1], activation='relu'))\n",
    "\n",
    "# First hidden layer (64 neurons, 'relu' activation)\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Second hidden layer (32 neurons, 'relu' activation)\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(len(unique(labels))+2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee37dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18617e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "88/88 [==============================] - 1s 5ms/step - loss: 1.8775 - val_loss: 1.8604\n",
      "Epoch 2/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8791 - val_loss: 1.8721\n",
      "Epoch 3/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8759 - val_loss: 1.9300\n",
      "Epoch 4/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8789 - val_loss: 1.8665\n",
      "Epoch 5/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8783 - val_loss: 1.8985\n",
      "Epoch 6/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8765 - val_loss: 1.9005\n",
      "Epoch 7/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8773 - val_loss: 1.8725\n",
      "Epoch 8/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8731 - val_loss: 1.8779\n",
      "Epoch 9/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8748 - val_loss: 1.8831\n",
      "Epoch 10/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8747 - val_loss: 1.8626\n",
      "Epoch 11/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8701 - val_loss: 1.8889\n",
      "Epoch 12/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8729 - val_loss: 1.8890\n",
      "Epoch 13/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8705 - val_loss: 1.8667\n",
      "Epoch 14/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8764 - val_loss: 1.8651\n",
      "Epoch 15/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8700 - val_loss: 1.8715\n",
      "Epoch 16/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8762 - val_loss: 1.8603\n",
      "Epoch 17/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8693 - val_loss: 1.9086\n",
      "Epoch 18/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8704 - val_loss: 1.8930\n",
      "Epoch 19/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8722 - val_loss: 1.8694\n",
      "Epoch 20/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8709 - val_loss: 1.8828\n",
      "Epoch 21/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8717 - val_loss: 1.8790\n",
      "Epoch 22/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8678 - val_loss: 1.9038\n",
      "Epoch 23/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8661 - val_loss: 1.8947\n",
      "Epoch 24/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8695 - val_loss: 1.8728\n",
      "Epoch 25/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8758 - val_loss: 1.8955\n",
      "Epoch 26/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8706 - val_loss: 1.8956\n",
      "Epoch 27/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8674 - val_loss: 1.8996\n",
      "Epoch 28/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8719 - val_loss: 1.8827\n",
      "Epoch 29/150\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.8763 - val_loss: 1.8732\n",
      "Epoch 30/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8703 - val_loss: 1.8809\n",
      "Epoch 31/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8681 - val_loss: 1.8723\n",
      "Epoch 32/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8693 - val_loss: 1.8773\n",
      "Epoch 33/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8730 - val_loss: 1.8705\n",
      "Epoch 34/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8641 - val_loss: 1.8952\n",
      "Epoch 35/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8620 - val_loss: 1.8676\n",
      "Epoch 36/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8650 - val_loss: 1.8710\n",
      "Epoch 37/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8671 - val_loss: 1.8995\n",
      "Epoch 38/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8633 - val_loss: 1.9221\n",
      "Epoch 39/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8707 - val_loss: 1.8910\n",
      "Epoch 40/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8624 - val_loss: 1.8844\n",
      "Epoch 41/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8629 - val_loss: 1.8852\n",
      "Epoch 42/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8597 - val_loss: 1.8778\n",
      "Epoch 43/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8607 - val_loss: 1.8714\n",
      "Epoch 44/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8656 - val_loss: 1.9117\n",
      "Epoch 45/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8593 - val_loss: 1.8813\n",
      "Epoch 46/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8624 - val_loss: 1.9019\n",
      "Epoch 47/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8678 - val_loss: 1.9088\n",
      "Epoch 48/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8649 - val_loss: 1.8795\n",
      "Epoch 49/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8614 - val_loss: 1.9049\n",
      "Epoch 50/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8673 - val_loss: 1.8850\n",
      "Epoch 51/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8629 - val_loss: 1.8908\n",
      "Epoch 52/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8650 - val_loss: 1.8770\n",
      "Epoch 53/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8607 - val_loss: 1.8883\n",
      "Epoch 54/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8572 - val_loss: 1.8963\n",
      "Epoch 55/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8589 - val_loss: 1.8919\n",
      "Epoch 56/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8560 - val_loss: 1.9351\n",
      "Epoch 57/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8615 - val_loss: 1.8804\n",
      "Epoch 58/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8562 - val_loss: 1.8994\n",
      "Epoch 59/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8559 - val_loss: 1.8822\n",
      "Epoch 60/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8565 - val_loss: 1.9013\n",
      "Epoch 61/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8582 - val_loss: 1.9009\n",
      "Epoch 62/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8559 - val_loss: 1.8957\n",
      "Epoch 63/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8579 - val_loss: 1.9056\n",
      "Epoch 64/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8583 - val_loss: 1.9098\n",
      "Epoch 65/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8548 - val_loss: 1.8810\n",
      "Epoch 66/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8575 - val_loss: 1.8940\n",
      "Epoch 67/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8566 - val_loss: 1.8839\n",
      "Epoch 68/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8537 - val_loss: 1.8759\n",
      "Epoch 69/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8540 - val_loss: 1.9093\n",
      "Epoch 70/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8559 - val_loss: 1.8787\n",
      "Epoch 71/150\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 1.8555 - val_loss: 1.8847\n",
      "Epoch 72/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8556 - val_loss: 1.8889\n",
      "Epoch 73/150\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.8552 - val_loss: 1.8882\n",
      "Epoch 74/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8531 - val_loss: 1.8790\n",
      "Epoch 75/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8520 - val_loss: 1.8988\n",
      "Epoch 76/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8601 - val_loss: 1.8822\n",
      "Epoch 77/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8568 - val_loss: 1.8992\n",
      "Epoch 78/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8536 - val_loss: 1.8851\n",
      "Epoch 79/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8512 - val_loss: 1.8898\n",
      "Epoch 80/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8532 - val_loss: 1.8944\n",
      "Epoch 81/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8548 - val_loss: 1.8888\n",
      "Epoch 82/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8530 - val_loss: 1.8919\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 8ms/step - loss: 1.8537 - val_loss: 1.8873\n",
      "Epoch 84/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8489 - val_loss: 1.9098\n",
      "Epoch 85/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8577 - val_loss: 1.9195\n",
      "Epoch 86/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8479 - val_loss: 1.8943\n",
      "Epoch 87/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8495 - val_loss: 1.8957\n",
      "Epoch 88/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8575 - val_loss: 1.8904\n",
      "Epoch 89/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8520 - val_loss: 1.8917\n",
      "Epoch 90/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8512 - val_loss: 1.8867\n",
      "Epoch 91/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8461 - val_loss: 1.8907\n",
      "Epoch 92/150\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.8462 - val_loss: 1.9206\n",
      "Epoch 93/150\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.8501 - val_loss: 1.8940\n",
      "Epoch 94/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8492 - val_loss: 1.8950\n",
      "Epoch 95/150\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.8499 - val_loss: 1.8862\n",
      "Epoch 96/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.8476 - val_loss: 1.8849\n",
      "Epoch 97/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8421 - val_loss: 1.8973\n",
      "Epoch 98/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8472 - val_loss: 1.9180\n",
      "Epoch 99/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8524 - val_loss: 1.8897\n",
      "Epoch 100/150\n",
      "86/88 [============================>.] - ETA: 0s - loss: 1.8474"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=150, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09b7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.280\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat = argmax(yhat, axis=-1).astype('int')\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
