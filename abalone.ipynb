{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50bcd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "766a7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fee36630",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "dataframe = read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcef0270",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataframe.values\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "data, labels = X.astype('float'), y.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44859ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.33, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62fce406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=data.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# First hidden layer (64 neurons, 'relu' activation)\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Second hidden layer (32 neurons, 'relu' activation)\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(len(unique(labels))+2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee37dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.01\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\")\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18617e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "88/88 [==============================] - 2s 7ms/step - loss: 3.0493 - val_loss: 3.2435\n",
      "Epoch 2/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.5598 - val_loss: 2.9408\n",
      "Epoch 3/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.3261 - val_loss: 2.6657\n",
      "Epoch 4/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.1877 - val_loss: 2.3456\n",
      "Epoch 5/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.1212 - val_loss: 2.2089\n",
      "Epoch 6/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.0621 - val_loss: 2.0448\n",
      "Epoch 7/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.0218 - val_loss: 2.0278\n",
      "Epoch 8/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 2.0037 - val_loss: 2.0155\n",
      "Epoch 9/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9787 - val_loss: 1.9178\n",
      "Epoch 10/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9677 - val_loss: 1.9628\n",
      "Epoch 11/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9572 - val_loss: 2.0005\n",
      "Epoch 12/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9406 - val_loss: 1.9329\n",
      "Epoch 13/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.9511 - val_loss: 2.0041\n",
      "Epoch 14/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.9338 - val_loss: 1.9599\n",
      "Epoch 15/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.9369 - val_loss: 1.9617\n",
      "Epoch 16/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.9174 - val_loss: 1.9324\n",
      "Epoch 17/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9190 - val_loss: 1.9496\n",
      "Epoch 18/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9095 - val_loss: 2.1622\n",
      "Epoch 19/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9153 - val_loss: 1.9812\n",
      "Epoch 20/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.9097 - val_loss: 1.9345\n",
      "Epoch 21/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.9102 - val_loss: 1.9801\n",
      "Epoch 22/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9064 - val_loss: 1.9818\n",
      "Epoch 23/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.9039 - val_loss: 1.9738\n",
      "Epoch 24/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8984 - val_loss: 1.9132\n",
      "Epoch 25/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8933 - val_loss: 1.9561\n",
      "Epoch 26/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8936 - val_loss: 1.9563\n",
      "Epoch 27/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8956 - val_loss: 1.9498\n",
      "Epoch 28/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8753 - val_loss: 1.9887\n",
      "Epoch 29/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8752 - val_loss: 1.8886\n",
      "Epoch 30/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8824 - val_loss: 1.9024\n",
      "Epoch 31/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8764 - val_loss: 1.9556\n",
      "Epoch 32/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8766 - val_loss: 1.9154\n",
      "Epoch 33/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8739 - val_loss: 1.9238\n",
      "Epoch 34/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8827 - val_loss: 2.0091\n",
      "Epoch 35/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8800 - val_loss: 1.8843\n",
      "Epoch 36/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8723 - val_loss: 2.0859\n",
      "Epoch 37/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8561 - val_loss: 1.9097\n",
      "Epoch 38/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8686 - val_loss: 1.9561\n",
      "Epoch 39/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8594 - val_loss: 2.0699\n",
      "Epoch 40/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8650 - val_loss: 1.9541\n",
      "Epoch 41/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8587 - val_loss: 2.0139\n",
      "Epoch 42/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8832 - val_loss: 1.9592\n",
      "Epoch 43/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8639 - val_loss: 1.9316\n",
      "Epoch 44/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8663 - val_loss: 1.9311\n",
      "Epoch 45/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8539 - val_loss: 2.0103\n",
      "Epoch 46/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8502 - val_loss: 1.9233\n",
      "Epoch 47/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8445 - val_loss: 1.9269\n",
      "Epoch 48/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8525 - val_loss: 2.1011\n",
      "Epoch 49/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8439 - val_loss: 1.9637\n",
      "Epoch 50/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8488 - val_loss: 1.9305\n",
      "Epoch 51/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8384 - val_loss: 1.9724\n",
      "Epoch 52/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8298 - val_loss: 1.9441\n",
      "Epoch 53/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8363 - val_loss: 1.9654\n",
      "Epoch 54/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8420 - val_loss: 1.9409\n",
      "Epoch 55/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8222 - val_loss: 2.0246\n",
      "Epoch 56/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8322 - val_loss: 1.9444\n",
      "Epoch 57/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8243 - val_loss: 1.9182\n",
      "Epoch 58/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8237 - val_loss: 2.3499\n",
      "Epoch 59/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8274 - val_loss: 1.9294\n",
      "Epoch 60/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8272 - val_loss: 2.0015\n",
      "Epoch 61/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8182 - val_loss: 2.1845\n",
      "Epoch 62/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8360 - val_loss: 1.9650\n",
      "Epoch 63/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8134 - val_loss: 1.9244\n",
      "Epoch 64/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8223 - val_loss: 2.0821\n",
      "Epoch 65/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8276 - val_loss: 1.9155\n",
      "Epoch 66/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8178 - val_loss: 1.9588\n",
      "Epoch 67/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8237 - val_loss: 2.0359\n",
      "Epoch 68/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8147 - val_loss: 1.9657\n",
      "Epoch 69/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8085 - val_loss: 1.9606\n",
      "Epoch 70/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8040 - val_loss: 1.9816\n",
      "Epoch 71/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7823 - val_loss: 2.0180\n",
      "Epoch 72/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7990 - val_loss: 1.9635\n",
      "Epoch 73/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7978 - val_loss: 1.9386\n",
      "Epoch 74/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7999 - val_loss: 1.9309\n",
      "Epoch 75/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7983 - val_loss: 1.9387\n",
      "Epoch 76/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7943 - val_loss: 1.9328\n",
      "Epoch 77/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8001 - val_loss: 2.0708\n",
      "Epoch 78/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7888 - val_loss: 2.0238\n",
      "Epoch 79/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8009 - val_loss: 2.0656\n",
      "Epoch 80/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.8026 - val_loss: 1.9707\n",
      "Epoch 81/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7586 - val_loss: 2.0222\n",
      "Epoch 82/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7812 - val_loss: 1.9418\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7944 - val_loss: 1.9648\n",
      "Epoch 84/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7664 - val_loss: 1.9832\n",
      "Epoch 85/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7848 - val_loss: 1.9784\n",
      "Epoch 86/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7767 - val_loss: 2.0878\n",
      "Epoch 87/150\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7783 - val_loss: 2.0832\n",
      "Epoch 88/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7865 - val_loss: 1.9968\n",
      "Epoch 89/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7849 - val_loss: 1.9687\n",
      "Epoch 90/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7648 - val_loss: 1.9746\n",
      "Epoch 91/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7639 - val_loss: 1.9800\n",
      "Epoch 92/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7650 - val_loss: 2.0111\n",
      "Epoch 93/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7681 - val_loss: 2.0081\n",
      "Epoch 94/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7690 - val_loss: 2.0062\n",
      "Epoch 95/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7649 - val_loss: 2.0079\n",
      "Epoch 96/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7573 - val_loss: 2.0245\n",
      "Epoch 97/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7563 - val_loss: 2.0328\n",
      "Epoch 98/150\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.7543 - val_loss: 2.0402\n",
      "Epoch 99/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7490 - val_loss: 2.0521\n",
      "Epoch 100/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7610 - val_loss: 2.0021\n",
      "Epoch 101/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7487 - val_loss: 2.0513\n",
      "Epoch 102/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7561 - val_loss: 2.0704\n",
      "Epoch 103/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7676 - val_loss: 2.0455\n",
      "Epoch 104/150\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.7573 - val_loss: 2.0118\n",
      "Epoch 105/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7430 - val_loss: 1.9810\n",
      "Epoch 106/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7266 - val_loss: 1.9887\n",
      "Epoch 107/150\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.7357 - val_loss: 2.0576\n",
      "Epoch 108/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7350 - val_loss: 2.0071\n",
      "Epoch 109/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7432 - val_loss: 2.0038\n",
      "Epoch 110/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7361 - val_loss: 2.0239\n",
      "Epoch 111/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7305 - val_loss: 2.0801\n",
      "Epoch 112/150\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.7169 - val_loss: 2.0100\n",
      "Epoch 113/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7426 - val_loss: 2.0989\n",
      "Epoch 114/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7369 - val_loss: 2.0138\n",
      "Epoch 115/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7371 - val_loss: 2.0130\n",
      "Epoch 116/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7237 - val_loss: 2.0696\n",
      "Epoch 117/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7326 - val_loss: 1.9977\n",
      "Epoch 118/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7210 - val_loss: 2.0248\n",
      "Epoch 119/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7398 - val_loss: 1.9977\n",
      "Epoch 120/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7205 - val_loss: 2.0556\n",
      "Epoch 121/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7300 - val_loss: 2.1390\n",
      "Epoch 122/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7051 - val_loss: 2.0036\n",
      "Epoch 123/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7240 - val_loss: 2.0388\n",
      "Epoch 124/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7062 - val_loss: 2.0296\n",
      "Epoch 125/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7277 - val_loss: 2.0825\n",
      "Epoch 126/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7279 - val_loss: 2.0675\n",
      "Epoch 127/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7089 - val_loss: 2.1241\n",
      "Epoch 128/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7122 - val_loss: 2.0476\n",
      "Epoch 129/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7158 - val_loss: 2.0323\n",
      "Epoch 130/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7221 - val_loss: 2.0250\n",
      "Epoch 131/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7207 - val_loss: 2.0851\n",
      "Epoch 132/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6932 - val_loss: 2.0117\n",
      "Epoch 133/150\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.7219 - val_loss: 2.0487\n",
      "Epoch 134/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6977 - val_loss: 2.1090\n",
      "Epoch 135/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7029 - val_loss: 2.0659\n",
      "Epoch 136/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6897 - val_loss: 2.0885\n",
      "Epoch 137/150\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7029 - val_loss: 2.1035\n",
      "Epoch 138/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6862 - val_loss: 2.0959\n",
      "Epoch 139/150\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.6959 - val_loss: 2.0508\n",
      "Epoch 140/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7024 - val_loss: 2.2322\n",
      "Epoch 141/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7027 - val_loss: 2.0911\n",
      "Epoch 142/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6976 - val_loss: 2.0085\n",
      "Epoch 143/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6935 - val_loss: 2.0852\n",
      "Epoch 144/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6909 - val_loss: 2.1711\n",
      "Epoch 145/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.7020 - val_loss: 2.0453\n",
      "Epoch 146/150\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.6849 - val_loss: 2.1452\n",
      "Epoch 147/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6908 - val_loss: 2.1169\n",
      "Epoch 148/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6890 - val_loss: 2.0826\n",
      "Epoch 149/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6764 - val_loss: 2.0448\n",
      "Epoch 150/150\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6777 - val_loss: 2.1396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f549b9d8430>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=150, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a09b7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.226\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat = argmax(yhat, axis=-1).astype('int')\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
